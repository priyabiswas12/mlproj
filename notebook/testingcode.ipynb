{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bffda27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "# Modelling\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression, Ridge,Lasso\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f2d4517",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/stud.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3aeaf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6d20564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "\n",
    "from src.exception import CustomException\n",
    "from src.logger import logging\n",
    "import os\n",
    "\n",
    "from src.utils import save_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afe9f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@dataclass\n",
    "class DataTransformationConfig:\n",
    "    preprocessor_obj_file_path=os.path.join('artifacts',\"preprocessor.pkl\") #output is stored here ie artifacts\\proprocessor.pkl\n",
    "\n",
    "\n",
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self):\n",
    "        self.data_transformation_config=DataTransformationConfig()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def get_data_transformer_object(self): #outputs preprocessed object\n",
    "        '''\n",
    "        This function is responsible for data transformation based on diff types of data\n",
    "        \n",
    "        '''\n",
    "        try:\n",
    "            numerical_columns = [\"writing_score\", \"reading_score\"]\n",
    "            categorical_columns = [\n",
    "                \"gender\",\n",
    "                \"race_ethnicity\",\n",
    "                \"parental_level_of_education\",\n",
    "                \"lunch\",\n",
    "                \"test_preparation_course\",\n",
    "            ]\n",
    "\n",
    "        \n",
    "            num_pipeline= Pipeline(\n",
    "                steps=[\n",
    "                (\"imputer\",SimpleImputer(strategy=\"median\")), #handling missing values\n",
    "                (\"scaler\",StandardScaler()) #scaling\n",
    "\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            cat_pipeline=Pipeline(\n",
    "\n",
    "                steps=[\n",
    "                (\"imputer\",SimpleImputer(strategy=\"most_frequent\")),\n",
    "                (\"one_hot_encoder\",OneHotEncoder()),\n",
    "                (\"scaler\",StandardScaler(with_mean=False))\n",
    "                ]\n",
    "\n",
    "            )\n",
    ")\n",
    "\n",
    "            preprocessor=ColumnTransformer(\n",
    "                [\n",
    "                (\"num_pipeline\",num_pipeline,numerical_columns),\n",
    "                (\"cat_pipelines\",cat_pipeline,categorical_columns)\n",
    "\n",
    "                ]\n",
    "\n",
    "\n",
    "            )\n",
    "\n",
    "            return preprocessor\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise CustomException(e,sys)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    def initiate_data_transformation(self,train_path,test_path):\n",
    "\n",
    "        try:\n",
    "            train_df=pd.read_csv(train_path)\n",
    "            test_df=pd.read_csv(test_path)\n",
    "\n",
    "            logging.info(\"Read train and test data completed\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            logging.info(\"Obtaining preprocessing object\")\n",
    "\n",
    "            preprocessing_obj=self.get_data_transformer_object() #calling the previous function defined here which gives you preprocessed ob\n",
    "\n",
    "            target_column_name=\"math_score\"\n",
    "            numerical_columns = [\"writing_score\", \"reading_score\"]\n",
    "\n",
    "            input_feature_train_df=train_df.drop(columns=[target_column_name],axis=1)\n",
    "            target_feature_train_df=train_df[target_column_name]\n",
    "\n",
    "            input_feature_test_df=test_df.drop(columns=[target_column_name],axis=1)\n",
    "            target_feature_test_df=test_df[target_column_name]\n",
    "\n",
    "            logging.info(\n",
    "                f\"Applying preprocessing object on training dataframe and testing dataframe.\"\n",
    "            )\n",
    "\n",
    "            input_feature_train_arr=preprocessing_obj.fit_transform(input_feature_train_df)\n",
    "            input_feature_test_arr=preprocessing_obj.transform(input_feature_test_df)\n",
    "\n",
    "            train_arr = np.c_[\n",
    "                input_feature_train_arr, np.array(target_feature_train_df)\n",
    "            ]\n",
    "            test_arr = np.c_[input_feature_test_arr, np.array(target_feature_test_df)]\n",
    "\n",
    "            logging.info(f\"Saved preprocessing object.\")\n",
    "\n",
    "            save_object(\n",
    "\n",
    "                file_path=self.data_transformation_config.preprocessor_obj_file_path,\n",
    "                obj=preprocessing_obj\n",
    "\n",
    "            )\n",
    "\n",
    "            return (\n",
    "                train_arr,\n",
    "                test_arr,\n",
    "                self.data_transformation_config.preprocessor_obj_file_path,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            raise CustomException(e,sys)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_transformation=DataTransformation()\n",
    "train_arr,test_arr,_=data_transformation.initiate_data_transformation(train_data,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb714a28",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (2234486572.py, line 46)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\priya\\AppData\\Local\\Temp\\ipykernel_51092\\2234486572.py\"\u001b[1;36m, line \u001b[1;32m46\u001b[0m\n\u001b[1;33m    return preprocessor\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def get_data_transformer_object(): #outputs preprocessed object\n",
    "        '''\n",
    "        This function is responsible for data transformation based on diff types of data\n",
    "        \n",
    "        '''\n",
    "        try:\n",
    "            numerical_columns = [\"writing_score\", \"reading_score\"]\n",
    "            categorical_columns = [\n",
    "                \"gender\",\n",
    "                \"race_ethnicity\",\n",
    "                \"parental_level_of_education\",\n",
    "                \"lunch\",\n",
    "                \"test_preparation_course\",\n",
    "            ]\n",
    "\n",
    "        \n",
    "            num_pipeline= Pipeline(\n",
    "                steps=[\n",
    "                (\"imputer\",SimpleImputer(strategy=\"median\")), #handling missing values\n",
    "                (\"scaler\",StandardScaler()) #scaling\n",
    "\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            cat_pipeline=Pipeline(\n",
    "\n",
    "                steps=[\n",
    "                (\"imputer\",SimpleImputer(strategy=\"most_frequent\")),\n",
    "                (\"one_hot_encoder\",OneHotEncoder()),\n",
    "                (\"scaler\",StandardScaler(with_mean=False))\n",
    "                ]\n",
    "\n",
    "            )\n",
    "\n",
    "\n",
    "            preprocessor=ColumnTransformer(\n",
    "                [\n",
    "                (\"num_pipeline\",num_pipeline,numerical_columns),\n",
    "                (\"cat_pipelines\",cat_pipeline,categorical_columns)\n",
    "\n",
    "                ]\n",
    "\n",
    "\n",
    "            )\n",
    "\n",
    "            return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dedc0433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initiate_data_transformation(train_path,test_path):\n",
    "\n",
    "    try:\n",
    "        train_df=pd.read_csv(train_path)\n",
    "        test_df=pd.read_csv(test_path)\n",
    "\n",
    "        logging.info(\"Read train and test data completed\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        logging.info(\"Obtaining preprocessing object\")\n",
    "\n",
    "        preprocessing_obj=self.get_data_transformer_object() #calling the previous function defined here which gives you preprocessed ob\n",
    "\n",
    "        target_column_name=\"math_score\"\n",
    "        numerical_columns = [\"writing_score\", \"reading_score\"]\n",
    "\n",
    "        input_feature_train_df=train_df.drop(columns=[target_column_name],axis=1)\n",
    "        target_feature_train_df=train_df[target_column_name]\n",
    "\n",
    "        input_feature_test_df=test_df.drop(columns=[target_column_name],axis=1)\n",
    "        target_feature_test_df=test_df[target_column_name]\n",
    "\n",
    "        logging.info(\n",
    "            f\"Applying preprocessing object on training dataframe and testing dataframe.\"\n",
    "        )\n",
    "\n",
    "        input_feature_train_arr=preprocessing_obj.fit_transform(input_feature_train_df)\n",
    "        input_feature_test_arr=preprocessing_obj.transform(input_feature_test_df)\n",
    "\n",
    "        train_arr = np.c_[\n",
    "            input_feature_train_arr, np.array(target_feature_train_df)\n",
    "        ]\n",
    "        test_arr = np.c_[input_feature_test_arr, np.array(target_feature_test_df)]\n",
    "\n",
    "        logging.info(f\"Saved preprocessing object.\")\n",
    "\n",
    "        save_object(\n",
    "\n",
    "            file_path=self.data_transformation_config.preprocessor_obj_file_path,\n",
    "            obj=preprocessing_obj\n",
    "\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            train_arr,\n",
    "            test_arr,\n",
    "            self.data_transformation_config.preprocessor_obj_file_path,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        raise CustomException(e,sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9d28c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformation=DataTransformation()\n",
    "train_arr,test_arr,_=data_transformation.initiate_data_transformation(train_data,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8784d54e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc41b90d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
